"""
Code used for running the analyses of Problems 17, 18, 19, and 20. DO
NOT EDIT THIS FILE.
"""
from typing import List, Optional, Union

import matplotlib.pyplot as plt
import torch
from nltk.tokenize import word_tokenize
from sklearn.decomposition import PCA
from sklearn.metrics import confusion_matrix

from data_loader import Dataset
from models import MLPPosTagger, RNNPosTagger


def print_cm(predictions: List[int], targets: List[int],
             pos_tag_names: List[str], hide_zeroes: bool = False,
             hide_diagonal: bool = False,
             hide_threshold: Optional[float] = None):
    """
    Computes and prints a confusion matrix.

    :param predictions: The predictions made by a model
    :param targets: The target POS tags that the predictions are
        evaluated against
    :param pos_tag_names: The names of each of the possible POS tags.
        pos_tag_names[i] should be the name of the POS tag with index i
        for all possible i
    :param hide_zeroes: If True, cells with a value of 0 will be shown
        as blank cells
    :param hide_diagonal: If True, cells on the diagonal will be shown
        as blank cells
    :param hide_threshold: If a value is provided for this keyword
        parameter, then cells with a value below this number will be
        shown as blank cells
    """
    targets = [pos_tag_names[int(target)] for target in targets]
    predictions = [pos_tag_names[int(pred)] for pred in predictions]
    cm = confusion_matrix(targets, predictions, labels=pos_tag_names)

    columnwidth = max(
        [len(x) for x in pos_tag_names] + [5])  # 5 is value length
    empty_cell = " " * columnwidth

    # Print header
    print("    " + empty_cell, end=" ")
    for label in pos_tag_names:
        print("%{0}s".format(columnwidth) % label, end=" ")
    print()

    # Print rows
    for i, label1 in enumerate(pos_tag_names):
        print("    %{0}s".format(columnwidth) % label1, end=" ")
        for j in range(len(pos_tag_names)):
            cell = "%{0}.1d".format(columnwidth) % cm[i, j]
            if hide_zeroes:
                cell = cell if float(cm[i, j]) != 0 else empty_cell
            if hide_diagonal:
                cell = cell if i != j else empty_cell
            if hide_threshold is not None:
                cell = cell if cm[i, j] > hide_threshold else empty_cell
            print(cell, end=" ")
        print()


def eval_sent(model: Union[MLPPosTagger, RNNPosTagger],
              sentences: List[str]) -> List[List[str]]:
    """
    Runs a POS tagger on a batch of sentences, and returns the output.

    :param model: An MLP or RNN POS tagger
    :param sentences: A list of sentences. Each sentence is represented
        as an untokenized string
    :return: The output of model on sentences, represented as a batch of
        POS tag sequences
    """
    vocab = model.token_vocab
    pos_vocab = model.pos_tag_vocab

    # Tokenize the sentences and convert to indices
    sentence_idx: List[List[int]] = []
    for s in sentences:
        s = [w.lower() for w in word_tokenize(s)]
        s = [w if w in vocab else "[UNK]" for w in s]
        s_idx = [vocab.get_index(w) for w in s]
        sentence_idx.append(s_idx)

    pos_tag_pad_index = pos_vocab.get_index("[PAD]")
    blank_pos_tags = [[pos_tag_pad_index] * len(s) for s in sentence_idx]
    dataset = Dataset(sentence_idx, blank_pos_tags, vocab.get_index("[PAD]"),
                      pos_tag_pad_index, sort_by_length=False)

    # Run the model
    model_input, _ = next(dataset.get_batches(len(sentences)))
    model.eval()
    predictions = model(model_input).argmax(axis=-1)
    return [list(map(pos_vocab.get_form, p[s != model.token_pad_index]))
            for p, s in zip(predictions, model_input)]


def make_hidden_pca(model: RNNPosTagger, test_data: Dataset,
                    num_components: int = 10) -> PCA:
    """
    Finds the principal components of the hidden states generated by an
    RNN model on a given dataset.

    :param model: An RNN model
    :param test_data: The data on which model will generate hidden state
        vectors
    :param num_components: The number of principal components to compute
    :return: The PCA model fit on model's hidden state vectors
    """
    if model.hidden_size < num_components:
        raise ValueError("nl_ratio must be between 0 and 1")
    hv = _extract_hidden_vectors(model, test_data).detach().numpy()
    pca = PCA(n_components=num_components)
    pca.fit_transform(hv)
    return pca


def plot_sentences(model: RNNPosTagger, pca: PCA, sentences: List[List[str]],
                   i: int = 0, j: int = 1):
    """
    Plots two specified principal components of the hidden states
    generated by a model on a provided list of sentences.

    :param model: An RNN model
    :param pca: A PCA model that has been fit to hidden states
    :param sentences: A batch of sentences to plot, where each sentence
        is represented as a list of tokens
    :param i: The index of the PCA component that will be plotted on the
        x-axis. i=0 means PC1 will be plotted on the x-axis, i=1 means
        PC2 will be plotted on the x-axis, etc.
    :param j: The index of the PCA component that will be plotted on the
        y-axis. j=0 means PC1 will be plotted on the y-axis, j=1 means
        PC2 will be plotted on the y-axis, etc.
    """
    _ = eval_sent(model, sentences)
    hidden_states = model.rnn_hidden_states.detach().numpy()
    for k, s in enumerate(sentences):
        s = [w.lower() for w in word_tokenize(s)]
        hidden_pca = pca.transform(hidden_states[k, :len(s)])
        _plot_trajectory(hidden_pca[:, i], hidden_pca[:, j], s, i, j)


def _extract_hidden_vectors(model: Union[MLPPosTagger, RNNPosTagger],
                            test_data: Dataset) -> torch.Tensor:
    model.eval()
    pad_index = model.token_pad_index
    all_hidden_vectors: List[torch.FloatTensor] = []
    for sentences, _ in test_data.get_batches(100):
        # Run the model on the mini-batch
        _ = model(sentences)

        # Mask out [BOS] and [PAD]
        pad_mask = (sentences != pad_index).view(-1)
        hidden_vectors = model.rnn_hidden_states.reshape(-1, model.hidden_size)
        all_hidden_vectors.append(hidden_vectors[pad_mask])

    return torch.cat(all_hidden_vectors, dim=0)


def _plot_trajectory(pc_i: torch.Tensor, pc_j: torch.Tensor,
                     sentence: List[str], i: int, j: int):
    # Plot all the points
    plt.scatter(pc_i, pc_j)

    # Draw arrows
    head_width = (max(pc_i) - min(pc_i)) / 50
    for k in range(len(pc_i) - 1):
        plt.arrow(pc_i[k], pc_j[k], pc_i[k + 1] - pc_i[k],
                  pc_j[k + 1] - pc_j[k], head_width=head_width,
                  length_includes_head=True)

    # Draw labels
    for k, word in enumerate(sentence):
        plt.text(pc_i[k] + .03, pc_j[k] + .03, word, fontsize=9)

    plt.xlabel("PC{}".format(i + 1))
    plt.ylabel("PC{}".format(j + 1))
    plt.show()
